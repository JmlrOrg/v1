<html> 
 <head>
  <meta http-equiv="Content-type" content="text/html;charset=UTF-8">


<!-- Google Scholar Meta Data -->

<meta name="citation_title" content="Sparse Bayesian Learning and the Relevance Vector Machine">

  <meta name="citation_author" content="Tipping, Michael E.">

<meta name="citation_publication_date" content="2001">
<meta name="citation_journal_title" content="Journal of Machine Learning Research">
<meta name="citation_issn" content="ISSN 1533-7928">
<meta name="citation_volume" content="1">
<meta name="citation_issue" content="Jun">
<meta name="citation_firstpage" content="211">
<meta name="citation_lastpage" content="244">
<meta name="citation_pdf_url" content="http://www.jmlr.org/papers/volume1/tipping01a/tipping01a.pdf">
 
  <!--#include virtual="/css-scroll.txt"-->
<style>
. {font-family:verdana,helvetica,sans-serif}
a {text-decoration:none;color:#3030a0}
 </style>
<body>
 <div id="content">

<h2>Sparse Bayesian Learning and the Relevance Vector Machine</h2>
<p><b><i>Michael E. Tipping</b></i>; 
1(Jun):211-244, 2001.</p>
<h3>Abstract</h3>
  This paper introduces a general Bayesian framework for obtaining
  sparse solutions to regression and classification tasks
  utilising models linear in the parameters. Although this framework
  is fully general, we illustrate our approach with a particular
  specialisation that we denote the 'relevance vector machine' (RVM),
  a model of identical functional form to the popular and
  state-of-the-art 'support vector machine' (SVM). We demonstrate that
  by exploiting a probabilistic Bayesian learning framework, we can
  derive accurate prediction models which typically utilise
  dramatically fewer basis functions than a comparable SVM while
  offering a number of additional advantages. These include the
  benefits of probabilistic predictions, automatic estimation of
  'nuisance' parameters, and the facility to utilise arbitrary basis
  functions (e.g. non-'Mercer' kernels).
  <p>
  We detail the Bayesian framework and associated learning algorithm
  for the RVM, and give some illustrative examples of its application
  along with some comparative benchmarks. We offer some explanation
  for the exceptional degree of sparsity obtained, and discuss and
  demonstrate some of the advantageous features, and potential
  extensions, of Bayesian relevance learning.
<p><font color=gray>[abs]</font>
<a target=_blank href=http://www.jmlr.org/papers/volume1/tipping01a/tipping01a.pdf>[pdf]</a>
<a target=_blank href=http://www.jmlr.org/papers/volume1/tipping01a/tipping01a.ps.gz>[ps.gz]</a>
<a target=_blank href=http://www.jmlr.org/papers/volume1/tipping01a/tipping01a.ps>[ps]</a>
</div> 
 <!--#include virtual="/nav-bar.txt"--> 
  </body>
 </html>
